{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10183,"status":"ok","timestamp":1638103961530,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"UZ5XqGp4hzBr","outputId":"3d077722-f5ac-4184-a50a-536797c53c06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 4.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 36.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n","Requirement already satisfied: torch\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 30.3 MB/s \n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.20.14-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 49.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.0.0-\u003epytorch-transformers) (3.10.0.2)\n","Collecting botocore\u003c1.24.0,\u003e=1.23.14\n","  Downloading botocore-1.23.14-py3-none-any.whl (8.2 MB)\n","\u001b[K     |████████████████████████████████| 8.2 MB 38.3 MB/s \n","\u001b[?25hCollecting s3transfer\u003c0.6.0,\u003e=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n","\u001b[?25hCollecting jmespath\u003c1.0.0,\u003e=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting urllib3\u003c1.27,\u003e=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil\u003c3.0.0,\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore\u003c1.24.0,\u003e=1.23.14-\u003eboto3-\u003epytorch-transformers) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003c3.0.0,\u003e=2.1-\u003ebotocore\u003c1.24.0,\u003e=1.23.14-\u003eboto3-\u003epytorch-transformers) (1.15.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003epytorch-transformers) (2021.10.8)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 50.2 MB/s \n","\u001b[?25hRequirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003epytorch-transformers) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003epytorch-transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003epytorch-transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003epytorch-transformers) (7.1.2)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.20.14 botocore-1.23.14 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 urllib3-1.25.11\n"]}],"source":["!pip install pytorch-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5620,"status":"ok","timestamp":1638103967146,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"F1EDE73Tj0qa"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n","from torch.optim import Adam\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8087,"status":"ok","timestamp":1638103975230,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"1RS5jL4SkhOc","outputId":"d8755d5f-0de1-4f8e-87c0-18c52b599a58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 12.71 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}],"source":["# naver sentiment corpus\n","!git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1638103975899,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"KvdtqYt5mmQo","outputId":"65aeeef2-7354-46b8-f0a1-444a913d5bc6"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003edocument\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e9976970\u003c/td\u003e\n","      \u003ctd\u003e아 더빙.. 진짜 짜증나네요 목소리\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e3819312\u003c/td\u003e\n","      \u003ctd\u003e흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e10265843\u003c/td\u003e\n","      \u003ctd\u003e너무재밓었다그래서보는것을추천한다\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["         id                           document  label\n","0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                  너무재밓었다그래서보는것을추천한다      0"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_csv('./nsmc/ratings_train.txt', sep='\\t')\n","test_df = pd.read_csv('./nsmc/ratings_test.txt', sep='\\t')\n","train_df.head(3)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1638103975899,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"RLX6F44fzW7h"},"outputs":[],"source":["train_df.dropna(inplace=True)\n","test_df.dropna(inplace=True)\n","\n","train_df = train_df.sample(frac=0.4, random_state=999)\n","test_df = test_df.sample(frac=0.4, random_state=999)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1638103975900,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"PcFrRk6I0Ouz"},"outputs":[],"source":["class NsmcDataset(Dataset):\n","    ''' Naver Sentiment Movie Corpus Dataset '''\n","    def __init__(self, df):\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx, 1]\n","        label = self.df.iloc[idx, 2]\n","        return text, label"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1638103975900,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"FIuykKZj6vIg"},"outputs":[],"source":["nsmc_train_dataset = NsmcDataset(train_df)\n","train_loader = DataLoader(nsmc_train_dataset, batch_size=2, shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79213,"status":"ok","timestamp":1638104055106,"user":{"displayName":"정영주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18135311492009028423"},"user_tz":-540},"id":"7gULDMqn9DAw","outputId":"2e66d4d2-be39-4a94-a668-8496ae714293"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 995526/995526 [00:01\u003c00:00, 908033.94B/s] \n","100%|██████████| 625/625 [00:00\u003c00:00, 434660.92B/s]\n","100%|██████████| 714314041/714314041 [00:55\u003c00:00, 12869682.97B/s]\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"XmK-ZPvcbvOM"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"name":"stdout","output_type":"stream","text":["[Epoch 1/1] Iteration 500 -\u003e Train Loss: 0.6984, Accuracy: 0.510\n","[Epoch 1/1] Iteration 1000 -\u003e Train Loss: 0.6937, Accuracy: 0.506\n","[Epoch 1/1] Iteration 1500 -\u003e Train Loss: 0.6967, Accuracy: 0.492\n","[Epoch 1/1] Iteration 2000 -\u003e Train Loss: 0.6897, Accuracy: 0.540\n","[Epoch 1/1] Iteration 2500 -\u003e Train Loss: 0.6902, Accuracy: 0.560\n","[Epoch 1/1] Iteration 3000 -\u003e Train Loss: 0.6881, Accuracy: 0.546\n","[Epoch 1/1] Iteration 3500 -\u003e Train Loss: 0.6824, Accuracy: 0.575\n","[Epoch 1/1] Iteration 4000 -\u003e Train Loss: 0.6601, Accuracy: 0.611\n","[Epoch 1/1] Iteration 4500 -\u003e Train Loss: 0.6335, Accuracy: 0.635\n","[Epoch 1/1] Iteration 5000 -\u003e Train Loss: 0.5756, Accuracy: 0.706\n","[Epoch 1/1] Iteration 5500 -\u003e Train Loss: 0.5683, Accuracy: 0.715\n","[Epoch 1/1] Iteration 6000 -\u003e Train Loss: 0.5575, Accuracy: 0.712\n","[Epoch 1/1] Iteration 6500 -\u003e Train Loss: 0.5593, Accuracy: 0.713\n","[Epoch 1/1] Iteration 7000 -\u003e Train Loss: 0.5230, Accuracy: 0.748\n","[Epoch 1/1] Iteration 7500 -\u003e Train Loss: 0.5361, Accuracy: 0.728\n","[Epoch 1/1] Iteration 8000 -\u003e Train Loss: 0.4918, Accuracy: 0.763\n","[Epoch 1/1] Iteration 8500 -\u003e Train Loss: 0.5107, Accuracy: 0.754\n","[Epoch 1/1] Iteration 9000 -\u003e Train Loss: 0.4919, Accuracy: 0.757\n","[Epoch 1/1] Iteration 9500 -\u003e Train Loss: 0.4931, Accuracy: 0.768\n","[Epoch 1/1] Iteration 10000 -\u003e Train Loss: 0.4711, Accuracy: 0.786\n","[Epoch 1/1] Iteration 10500 -\u003e Train Loss: 0.4985, Accuracy: 0.755\n","[Epoch 1/1] Iteration 11000 -\u003e Train Loss: 0.5188, Accuracy: 0.744\n","[Epoch 1/1] Iteration 11500 -\u003e Train Loss: 0.4787, Accuracy: 0.782\n","[Epoch 1/1] Iteration 12000 -\u003e Train Loss: 0.4920, Accuracy: 0.772\n","[Epoch 1/1] Iteration 12500 -\u003e Train Loss: 0.4841, Accuracy: 0.765\n","[Epoch 1/1] Iteration 13000 -\u003e Train Loss: 0.4593, Accuracy: 0.779\n","[Epoch 1/1] Iteration 13500 -\u003e Train Loss: 0.4702, Accuracy: 0.789\n","[Epoch 1/1] Iteration 14000 -\u003e Train Loss: 0.5045, Accuracy: 0.751\n","[Epoch 1/1] Iteration 14500 -\u003e Train Loss: 0.4292, Accuracy: 0.810\n","[Epoch 1/1] Iteration 15000 -\u003e Train Loss: 0.4692, Accuracy: 0.790\n","[Epoch 1/1] Iteration 15500 -\u003e Train Loss: 0.4207, Accuracy: 0.806\n","[Epoch 1/1] Iteration 16000 -\u003e Train Loss: 0.4895, Accuracy: 0.770\n","[Epoch 1/1] Iteration 16500 -\u003e Train Loss: 0.4676, Accuracy: 0.785\n"]}],"source":["optimizer = Adam(model.parameters(), lr=1e-6)\n","\n","itr = 1\n","p_itr = 500\n","epochs = 1\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","\n","model.train()\n","for epoch in range(epochs):\n","    \n","    for text, label in train_loader:\n","        optimizer.zero_grad()\n","\n","        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","        sample = torch.tensor(padded_list)\n","        sample, label = sample.to(device), label.to(device)\n","        labels = torch.tensor(label)\n","        outputs = model(sample, labels=labels)\n","        loss, logits = outputs\n","\n","        pred = torch.argmax(F.softmax(logits), dim=1)\n","        correct = pred.eq(labels)\n","        total_correct += correct.sum().item()\n","        total_len += len(labels)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if itr % p_itr == 0:\n","            print('[Epoch {}/{}] Iteration {} -\u003e Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n","            total_loss = 0\n","            total_len = 0\n","            total_correct = 0\n","\n","        itr+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvLgd9qdrV3A"},"outputs":[],"source":["# evaluation\n","model.eval()\n","\n","nsmc_eval_dataset = NsmcDataset(test_df)\n","eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n","\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","for text, label in eval_loader:\n","    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","    sample = torch.tensor(padded_list)\n","    sample, label = sample.to(device), label.to(device)\n","    labels = torch.tensor(label)\n","    outputs = model(sample, labels=labels)\n","    _, logits = outputs\n","\n","    pred = torch.argmax(F.softmax(logits), dim=1)\n","    correct = pred.eq(labels)\n","    total_correct += correct.sum().item()\n","    total_len += len(labels)\n","\n","print('Test accuracy: ', total_correct / total_len)\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33xBTcv5_GDQ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BertForSequenceClassification 예제의 사본","provenance":[{"file_id":"https://github.com/zzaebok/PytorchBertExample/blob/master/BertForSequenceClassification_%EC%98%88%EC%A0%9C.ipynb","timestamp":1638103921778}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}